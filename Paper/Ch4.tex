% ------------------------------------------------------------------------
% -*-TeX-*- -*-Hard-*- Smart Wrapping
% ------------------------------------------------------------------------

%REF_1 - J.A. Hartigan (1975). Clustering algorithms. John Wiley & Sons, Inc.

%REF_2 - Joblove and Greenbergâ€™s (1978) HSL and HSV

\def\baselinestretch{1}

\chapter{Proposed Approach}

\def\baselinestretch{1.66}


%%% ----------------------------------------------------------------------

% intro text here
The proposed solution takes a counting-by-detection approach to solving the problem. It makes use of both image analysis and computer vision techniques and machine learning techniques. The detection of grains to be counted is carried out in a supervised learning manner and the image is manipulated using computer vision techniques. The system aims to first detect all instances of grains in a given image, then compute the count as the number of instances detected. FIG\_ illustrates the design of the system and its various components. The system first pre-processes images, extracting the regions of interest, then breaks the image into  thousands of sub-images. The sub-images are then passed to a classifier which has been trained initially and thus predicts whether a sub-image contains a grain or not. This chapter proposes a solution to the problem of counting the number of grains in an image. The proposed system is broken down into stages and each stage is described in this chapter.r

\smallskip

\begin{figure}[ht!]
\centering
\includegraphics[scale=2.5]{Placeholder}
\caption{Placeholder for diagram showing system overview and components}
\label{fig1}
\end{figure}

\smallskip

%%% ----------------------------------------------------------------------
\goodbreak
\section{Grain Counting Pipeline}
\subsection{Image Pre-processing}
The first step in the grain counting process is to identify and remove all parts of the given images that do not contain grains. The aim of this stage is to reduce the problem space by extracting only the regions of the images that we are concerned with - that is, the spikelets and grains. Region of Interest (ROI) extraction also makes the grain detection and counting process accurate. It removes sky, ground, leaves, and background regions from the image. Otherwise, parts of these regions could be wrongly detected as grains and counted.\\ \\
%
ROI extraction is achieved using \textit{segmentation-based object categorization}. This process applies spectral clustering to an image in order to partition the image into distinct regions, known as clusters, based on their colour. The pixels in a cluster are similar to each other in colour but different from pixels in other clusters. In this project, the \textit{\textbf{k-Means Clustering}}(REF\_1) algorithm is used to cluster the pixels. Given an image of $n$ pixels ($x_1, x_2, ..., x_n$) in the HSV space (REF\_2) where each element $x_i$ is a vector made up of that pixels hue, saturation and value, we partition the $n$ pixels into $k$ clusters, $C = \{C_1, C_2, ..., C_k\}$ in order to minimize the distance between every pixel and the mean pixel in each cluster. Mathematically, the spectral clustering via kmeans can be denoted as:

\begin{equation}
argmin \sum_{i=1}^{k}\sum_{x\in C_i} ||x - \mu_i||^2
\end{equation}

where $\mu_i$ is the mean HSV pixel vector in cluster $i$\\ \\
%
FIG\_ shows an illustration of the ROI process. The original image has spectral clustering applied to it as described above (with $k = 5$), and the result of this is shown in FIG\_(a). Each cluster is shown with a different colour overlayed over it. From this image, we can select the clusters which contain relevant information (grains) and do away with other clusters. FIG\_(b) illustrates this as it shows the resulting image after the red, green and purple clusters are removed. The resulting ROI image contains still contains all of the useful information (ie. grains) but only little else.
\begin{figure}[ht!]
%\centering
\begin{subfigure}{.5\textwidth}
%  \centering
\includegraphics[width=.9\linewidth,height=.7\linewidth,keepaspectratio]{clusters.png}
  \caption{Image showing cluster memberships}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
%  \centering
 \includegraphics[width=.9\linewidth,height=.7\linewidth,keepaspectratio]{roi.png}
  \caption{ROI image with useful clusters extracted}
  \label{fig:sub2}
\end{subfigure}
\caption{ROI extraction using spectral clustering}
\label{fig:test}
\end{figure}

\subsection{Sub-image Extraction}
The next step in the grain counting process is to break the extracted ROI image into tiny blocks. These blocks might contain grains or they might contain stalks and leaves that were overlooked in the ROI extraction process. A conceptual summary of the proposed system is that it counts which of these blocks contains a grain, thereby giving a grain count for the whole image. However, it is important to also note that one block might contain more than one grain or even only a portion of a grain. So if the conceptual description is applied, the result would not be very accurate. Strictly speaking, the system only yields an estimate of the grain count. To make this estimate as accurate as possible, the division of the image into blocks has to be done as precisely as possible, with blocks containing grains having either just one grain or a large portion of a grain in them.\\ \\
%
The blocks are extracted using a kernel convolution approach. The convolution matrix (or kernel) is an $M$-by-$N$ matrix containing all $1$s. First the image is transformed to greyscale to simplify the convolution process. Each time the kernel is applied, the result of the convolution is stored in a list. Edges are handled using a ``cropping'' approach. That is, if the kernel cannot completely be placed at an edge, that edge is simply ignored.
\begin{figure}[ht!]
\centering
\includegraphics[scale=0.6]{kernel}
\caption{Pseudocode of sub-image extraction using kernel method}
\label{fig1}
\end{figure}
In our implementation, we use a kernel of size $20$-by-$20$ giving square sub-images of length $20$. This value is ideal because it is large enough to contain one grain. Due to visual perspective issues, grains closer to the background appear smaller. A $20$-by-$20$ kernel is still small enough to contain only one or one and a bit more of a grain scaled down. Also, with a kernel of this size, the cropping edge handling approach is of no negative consequence as it highly unlikely that more than a minuscule number of grains will be in the remainder of the edge (which would be less than $20$ pixels wide).

\subsection{Classification}
This is the main step in the grain counting process. Here, the sub-images extracted from the previous step are classified as either containing a grain or not. In particular, a \textit{\textbf{Multi-Layer Perceptron (MLP)}} neural network is used for the classification. The neural network does not deal directly with the images as a whole, but rather with sub-images. Recall that our dataset contains only $13$ images which would not be anywhere near sufficient to properly train the neural network. However, because the neural network deals with sub-images, it can be trained using just one of the images in the dataset. When this one image is selected, it can then be broken down into its sub-images of size $20$-by-$20$. Each image yields $5000$ sub-images on average. This is more than sufficient for training the neural network. Unfortunately, the generated sub-images will still need to be labeled in order to be used for training the neural network. This would be a very time consuming and labour-intensive task. Because of this, only $350$ sub-images were hand selected and labeled. The neural network is then trained on these sub-images. When selecting sub-images to be used for training the neural network, care was taken to keep the training data balanced. That is, the numbers of grain sub-images and non-grain sub-images were fairly close. No one class dominated the selected sample.\\ \\
%
It is worth noting that the whole sub-images are not passed into the neural network. Instead, discriminative features are extracted from the sub-images to form feature vectors. We make use of textural features based on the textures of the sub-images. Generally speaking, textures are complex visual patterns that have characteristics such as brightness, colour and contrast. Because of this, texture is easily perceived by humans and is believed to be a rich source of
visual information. For each sub-image, the \textit{Gray Level Co-occurrence Matrix (GLCM)} is computed. From the GLCM, we then compute the following texture descriptors - \textit{energy}, \textit{homogeneity}, \textit{correlation} and \textit{dissimilarity}. Each of these descriptors is computed for when $\theta = 0^\circ, \theta = 45^\circ, \theta = 90^\circ$ and $\theta = 135^\circ$ and the distance, $d = 0$ to build a 16-dimension feature vector describing the sub-image.
\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3]{glcm_1}
\caption{Plot of GLCM descriptors demonstrating their discriminative power}
\label{fig1}
\end{figure}
This means that 16-element vectors are passed through the neural network, as opposed to $20$-by-$20$ matrices (400-element vectors). This saves memory and also allows the neural network to work faster as well. FIG\_ shows GLCM descriptors extracted from different parts of a wheat image and plotted against each other. From the figure, it can be seen that GLCM descriptors are able to adequately discriminate between grain regions and stalk regions. By using GLCM feature vectors instead of raw image data, we can boost the discriminative power of the neural network and improve the accuracy of the detection system.

\subsection{Employing the System to Counting}
Once the neural network is built, it can then be used for the detection of grains. Given a query image, it is passed through the pipeline. First, the query image goes through pre-processing to have the ROI extracted from it. The query ROI image is then broken into query sub-images. Next is the detection stage - the neural network is applied to the query sub-images to determine whether a given sub-image contains a grain or not. The number of sub-images classified as containing grains by the neural network is then returned as an estimate of the number of grains in the image.
\bigskip

%%% ----------------------------------------------------------------------
\goodbreak




\bigskip

%%% ----------------------------------------------------------------------


